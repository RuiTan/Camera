{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from line import *\n",
    "\n",
    "DATA_PATH = './capture/'\n",
    "THRESHOLD = 0.1\n",
    "GRAY_SUB_THRESHOLD = 0.5\n",
    "\n",
    "\n",
    "def edge_detection(img):\n",
    "    gaussian_blur = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "    canny = cv2.Canny(gaussian_blur, 35, 125)\n",
    "\n",
    "    _, threshold = cv2.threshold(img, 210, 255, cv2.THRESH_BINARY)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
    "    gradient = cv2.morphologyEx(threshold, cv2.MORPH_GRADIENT, kernel)\n",
    "    return canny, gradient\n",
    "\n",
    "\n",
    "def graySub(img1, img2):\n",
    "    img1_gray = cv2.cvtColor(img1, cv2.COLOR_RGB2GRAY).astype(float)\n",
    "    img2_gray = cv2.cvtColor(img2, cv2.COLOR_RGB2GRAY).astype(float)\n",
    "    sub = float_to_rgb(img1_gray - img2_gray)\n",
    "    return sub\n",
    "\n",
    "\n",
    "def float_to_rgb(img):\n",
    "    img = np.abs(img)\n",
    "    max = np.max(img)\n",
    "    min = np.min(img)\n",
    "    img = (img - min) / (max - min)\n",
    "    img = (img * 255).astype(np.uint8)\n",
    "    return img\n",
    "\n",
    "\n",
    "def filter(img, threshold):\n",
    "    img[img >= (255 * threshold)] = 255\n",
    "    img[img < (255 * threshold)] = 0\n",
    "    return img.astype(np.uint8)\n",
    "\n",
    "\n",
    "def norm(img):\n",
    "    max = np.max(img)\n",
    "    min = np.min(img)\n",
    "    img = (img - min) / (max - min)\n",
    "    return img\n",
    "\n",
    "\n",
    "def distance_to_camera(knownWidth, focalLength, perWidth):\n",
    "    return (knownWidth * focalLength) / perWidth\n",
    "\n",
    "\n",
    "def find_marker(image):\n",
    "    canny, _ = edge_detection(image)\n",
    "    _, cnts, _ = cv2.findContours(canny.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = sorted(cnts, key=cv2.contourArea)\n",
    "    cs = []\n",
    "    if len(cnts) <= 2:\n",
    "        cs.append(cv2.minAreaRect(cnts[-1]))\n",
    "        cs.append(cv2.minAreaRect(cnts[-1]))\n",
    "        return cs, False\n",
    "    else:\n",
    "        cs.append(cv2.minAreaRect(cnts[-1]))\n",
    "        cs.append(cv2.minAreaRect(cnts[-3]))\n",
    "        return cs, True\n",
    "\n",
    "\n",
    "def calc_pixel_length(length, pixels):\n",
    "    return length / pixels\n",
    "\n",
    "\n",
    "def video2frame(video_path, time_interval=1):\n",
    "    print('=====================================================')\n",
    "    print('开始拆分视频...')\n",
    "    vid_cap = cv2.VideoCapture(video_path)\n",
    "    success, image = vid_cap.read()\n",
    "    count = 0\n",
    "    frames = []\n",
    "    while success:\n",
    "        success, image = vid_cap.read()\n",
    "        count += 1\n",
    "        if count % time_interval == 0:\n",
    "            frames.append(image)\n",
    "    print('视频拆分完成...')\n",
    "    print('=====================================================')\n",
    "    return frames, (int(vid_cap.get(3)), int(vid_cap.get(4))), vid_cap.get(5)\n",
    "\n",
    "\n",
    "def frame2video(images, video_path, frame_size, fps=20):\n",
    "    print('=====================================================')\n",
    "    print('开始导出视频...')\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    videoWriter = cv2.VideoWriter(video_path, fourcc, fps, frame_size, True)\n",
    "    for i in images:\n",
    "        if i is not None:\n",
    "            videoWriter.write(i)\n",
    "    videoWriter.release()\n",
    "    print('视频导出成功...')\n",
    "    print('=====================================================')\n",
    "\n",
    "\n",
    "# def process_image(img, known_distance=24.0, known_height=148.9, known_width=71.06):\n",
    "def process_image(img, pixel_length=0.3, show=False, direction=0):\n",
    "    # img = cv2.imread('benchmark/boxes.png')\n",
    "    # cv2.imshow('canny', edge_detection(img)[0])\n",
    "    markers, flag = find_marker(img)\n",
    "    boxes = []\n",
    "    for marker in markers:\n",
    "        box = np.int0(cv2.boxPoints(marker))\n",
    "        boxes.append(box)\n",
    "        cv2.drawContours(img, [box], -1, (0, 255, 0), 2)\n",
    "\n",
    "    marker0 = boxes[0]\n",
    "    marker1 = boxes[1]\n",
    "\n",
    "    if direction == 0:\n",
    "        start = 0\n",
    "    else:\n",
    "        start = 1\n",
    "    len_ = None\n",
    "    point_ = None\n",
    "    for i in [start, start + 2]:\n",
    "        marker0_0 = Point(marker0[i][0], marker0[i][1])\n",
    "        marker0_1 = Point(marker0[(i + 1) % 4][0], marker0[(i + 1) % 4][1])\n",
    "        line = Line(marker0_0, marker0_1)\n",
    "        marker1_0 = Point(marker1[i % 4][0], marker1[(i) % 4][1])\n",
    "        marker1_1 = Point(marker1[(i + 1) % 4][0], marker1[(i + 1) % 4][1])\n",
    "        marker1_2 = Point(marker1[(i + 2) % 4][0], marker1[(i + 2) % 4][1])\n",
    "        marker1_3 = Point(marker1[(i + 3) % 4][0], marker1[(i + 3) % 4][1])\n",
    "        len1 = calculate_distance(marker1_0.x, marker1_0.y, line)\n",
    "        len2 = calculate_distance(marker1_1.x, marker1_1.y, line)\n",
    "        len3 = calculate_distance(marker1_2.x, marker1_2.y, line)\n",
    "        len4 = calculate_distance(marker1_3.x, marker1_3.y, line)\n",
    "        if len_ is None or min(len_) > min([len1, len2, len3, len4]):\n",
    "            len_ = [len1, len2, len3, len4]\n",
    "            point_ = [marker1_0, marker1_1, marker1_2, marker1_3]\n",
    "\n",
    "    #     print(len_)\n",
    "    #     for i in point_:\n",
    "    #         print(i.x, i.y)\n",
    "    indices = np.argsort(len_)\n",
    "#     print(indices)\n",
    "    len_ = [len_[indices[0]], len_[indices[1]]]\n",
    "    point_ = [point_[indices[0]], point_[indices[1]]]\n",
    "    #     print(len_)\n",
    "    #     for i in point_:\n",
    "    #         print(i.x, i.y)\n",
    "\n",
    "    cv2.circle(img, (point_[0].x, point_[0].y), 10, (0, 255, 0), 5)\n",
    "    cv2.circle(img, (point_[1].x, point_[1].y), 10, (0, 255, 0), 5)\n",
    "    cv2.putText(img, 'Min gap size: ' + str(format(len_[0], '.1f')) + 'mm', (point_[0].x+50, point_[0].y), cv2.FONT_HERSHEY_SIMPLEX, 1,\n",
    "                (0, 0, 0), 3)\n",
    "    cv2.putText(img, 'Max gap size: ' + str(format(len_[1], '.1f')) + 'mm', (point_[1].x+50, point_[1].y), cv2.FONT_HERSHEY_SIMPLEX, 1,\n",
    "                (0, 0, 0), 3)\n",
    "    # print(min_length)\n",
    "    if show:\n",
    "        cv2.imshow(\"img\", img)\n",
    "        cv2.waitKey(0)\n",
    "    return img, len1, len2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================\n",
      "开始拆分视频...\n",
      "视频拆分完成...\n",
      "=====================================================\n"
     ]
    }
   ],
   "source": [
    "target = 'rotate_boxes'\n",
    "frames, size, fps = video2frame('benchmark/'+target+'.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "608 (1920, 1080) 30.302526871895402\n"
     ]
    }
   ],
   "source": [
    "print(len(frames), size, fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/608 [00:00<00:32, 18.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================\n",
      "开始计算帧缝隙...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 608/608 [00:16<00:00, 37.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "计算完成...\n",
      "=====================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('=====================================================')\n",
    "print('开始计算帧缝隙...')\n",
    "gap_file = open('benchmark/'+target+'.txt', 'w')\n",
    "for i in tqdm(range(len(frames))):\n",
    "    if frames[i] is not None:\n",
    "        frames[i], min1, min2 = process_image(frames[i])\n",
    "        gap_file.write(str(format(min1, '.1f')) + ' ' + str(format(min2, '.1f')) + '\\n')\n",
    "gap_file.close()\n",
    "print('计算完成...')\n",
    "print('=====================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================\n",
      "开始导出视频...\n",
      "视频导出成功...\n",
      "=====================================================\n"
     ]
    }
   ],
   "source": [
    "frame2video(frames, 'benchmark/'+target+'.avi', size, fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}